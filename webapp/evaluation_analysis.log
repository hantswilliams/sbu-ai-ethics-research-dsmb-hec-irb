2025-07-14 19:11:46,887 - evaluation_analysis - INFO - Using database at /Users/hantswilliams/Development/python/sbu-ai-ethics-research-dsmb-hec-irb/data/results.db
2025-07-14 19:11:46,891 - evaluation_analysis - INFO - Loaded 18 responses from database
2025-07-14 19:11:46,892 - evaluation_analysis - INFO - Loaded 20 evaluations from database
2025-07-14 19:11:46,895 - evaluation_analysis - INFO - Loaded 20 evaluations from database
2025-07-14 19:11:46,901 - evaluation_analysis - INFO - Evaluations by evaluator:
evaluator_id
1    18
2     1
3     1
dtype: int64
2025-07-14 19:11:46,902 - evaluation_analysis - INFO - Evaluations by scenario:
case_id  scenario_filename  iteration
1        1_case.md          1            2
                            2            3
                            3            3
2        2_case.md          1            2
                            2            2
                            3            2
3        3_case.md          1            2
                            2            2
                            3            2
dtype: int64
2025-07-14 19:11:46,913 - evaluation_analysis - INFO - Average scores by vendor:
       relevance_score                  ... coherence_score                
                  mean       std count  ...            mean       std count
vendor                                  ...                                
Google        3.777778  1.394433     9  ...        3.444444  1.013794     9
OpenAI        3.363636  0.674200    11  ...        3.363636  0.809040    11

[2 rows x 12 columns]
2025-07-14 19:11:46,915 - evaluation_analysis - INFO - Overall average by vendor:
            mean       std  count
vendor                           
Google  3.638889  1.139566      9
OpenAI  3.409091  0.691671     11
2025-07-14 19:11:47,407 - evaluation_analysis - INFO - Score distribution plots saved
2025-07-14 19:11:47,673 - evaluation_analysis - INFO - Vendor comparison plots saved
2025-07-14 19:11:47,885 - evaluation_analysis - INFO - Model comparison plots saved
2025-07-14 19:11:47,900 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-07-14 19:11:47,902 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-07-14 19:11:47,967 - evaluation_analysis - INFO - Comprehensive evaluation report saved to /Users/hantswilliams/Development/python/sbu-ai-ethics-research-dsmb-hec-irb/data/evaluation_results/evaluation_report.html
2025-07-14 19:11:47,967 - evaluation_analysis - INFO - Evaluation analysis completed successfully
2025-07-15 09:15:16,776 - evaluation_analysis - INFO - Using database at /Users/hantswilliams/Development/python/sbu-ai-ethics-research-dsmb-hec-irb/data/results.db
2025-07-15 09:15:16,794 - evaluation_analysis - INFO - Loaded 4 responses from database
2025-07-15 09:15:16,800 - evaluation_analysis - INFO - Loaded 4 evaluations from database
2025-07-15 09:15:16,810 - evaluation_analysis - INFO - Loaded 4 evaluations from database
2025-07-15 09:15:16,859 - evaluation_analysis - INFO - Evaluations by evaluator:
evaluator_id
1    4
dtype: int64
2025-07-15 09:15:16,861 - evaluation_analysis - INFO - Evaluations by scenario:
case_id  scenario_filename  iteration
1        1_case.md          1            4
dtype: int64
2025-07-15 09:15:16,891 - evaluation_analysis - INFO - Average scores by vendor:
          relevance_score           correctness_score  ... fluency_score coherence_score          
                     mean std count              mean  ...         count            mean std count
vendor                                                 ...                                        
Anthropic             2.0 NaN     1               3.0  ...             1             4.0 NaN     1
GROK                  3.0 NaN     1               3.0  ...             1             3.0 NaN     1
Google                5.0 NaN     1               4.0  ...             1             2.0 NaN     1
OpenAI                4.0 NaN     1               5.0  ...             1             4.0 NaN     1

[4 rows x 12 columns]
2025-07-15 09:15:16,901 - evaluation_analysis - INFO - Overall average by vendor:
           mean  std  count
vendor                     
Anthropic  3.25  NaN      1
GROK       3.00  NaN      1
Google     3.75  NaN      1
OpenAI     4.25  NaN      1
2025-07-15 09:15:18,101 - evaluation_analysis - INFO - Score distribution plots saved
2025-07-15 09:15:19,012 - evaluation_analysis - INFO - Vendor comparison plots saved
2025-07-15 09:15:19,913 - evaluation_analysis - INFO - Model comparison plots saved
2025-07-15 09:15:19,957 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-07-15 09:15:19,962 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-07-15 09:15:20,121 - evaluation_analysis - INFO - Comprehensive evaluation report saved to /Users/hantswilliams/Development/python/sbu-ai-ethics-research-dsmb-hec-irb/data/evaluation_results/evaluation_report.html
2025-07-15 09:15:20,121 - evaluation_analysis - INFO - Evaluation analysis completed successfully
2025-07-15 09:27:55,811 - evaluation_analysis - INFO - Using database at /Users/hantswilliams/Development/python/sbu-ai-ethics-research-dsmb-hec-irb/data/results.db
2025-07-15 09:27:55,815 - evaluation_analysis - INFO - Loaded 4 responses from database
2025-07-15 09:27:55,816 - evaluation_analysis - INFO - Loaded 8 evaluations from database
2025-07-15 09:27:55,823 - evaluation_analysis - INFO - Loaded 8 evaluations from database
2025-07-15 09:27:55,835 - evaluation_analysis - INFO - Evaluations by evaluator:
evaluator_id
1    4
2    4
dtype: int64
2025-07-15 09:27:55,835 - evaluation_analysis - INFO - Evaluations by scenario:
case_id  scenario_filename  iteration
1        1_case.md          1            8
dtype: int64
2025-07-15 09:27:55,845 - evaluation_analysis - INFO - Average scores by vendor:
          relevance_score                  ... coherence_score                
                     mean       std count  ...            mean       std count
vendor                                     ...                                
Anthropic             2.5  0.707107     2  ...             3.5  0.707107     2
GROK                  3.0  0.000000     2  ...             3.0  0.000000     2
Google                3.5  2.121320     2  ...             1.5  0.707107     2
OpenAI                4.0  0.000000     2  ...             4.0  0.000000     2

[4 rows x 12 columns]
2025-07-15 09:27:55,846 - evaluation_analysis - INFO - Overall average by vendor:
           mean       std  count
vendor                          
Anthropic  3.25  0.000000      2
GROK       3.00  0.000000      2
Google     3.00  1.060660      2
OpenAI     4.00  0.353553      2
2025-07-15 09:27:56,446 - evaluation_analysis - INFO - Score distribution plots saved
2025-07-15 09:27:56,944 - evaluation_analysis - INFO - Vendor comparison plots saved
2025-07-15 09:27:57,332 - evaluation_analysis - INFO - Model comparison plots saved
2025-07-15 09:27:57,396 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-07-15 09:27:57,398 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-07-15 09:27:57,475 - evaluation_analysis - INFO - Comprehensive evaluation report saved to /Users/hantswilliams/Development/python/sbu-ai-ethics-research-dsmb-hec-irb/data/evaluation_results/evaluation_report.html
2025-07-15 09:27:57,475 - evaluation_analysis - INFO - Evaluation analysis completed successfully
