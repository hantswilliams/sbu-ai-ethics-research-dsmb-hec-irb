<html>
        <head>
            <title>AI Ethics Research Evaluation Analysis</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                h1, h2, h3 { color: #333366; }
                table { border-collapse: collapse; width: 100%; margin-bottom: 20px; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
                th { background-color: #f2f2f2; }
                img { max-width: 100%; height: auto; margin: 10px 0; }
                .section { margin-bottom: 30px; }
            </style>
        </head>
        <body>
            <h1>AI Ethics Research Evaluation Analysis</h1>
            <p>Generated on: 2025-07-25 20:26:34</p>
            
            <div class="section">
                <h2>Overview</h2>
                <p>Total evaluations analyzed: 857</p>
                <p>Vendors included: Anthropic, GROK, Google, OpenAI</p>
                <p>Models included: Google gemini-1.5-pro, Anthropic claude-3-opus-20240229, OpenAI gpt-4.1-nano, GROK grok-3-mini</p>
                <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Total Evaluations</th>
      <th>Unique Evaluators</th>
      <th>Unique Cases</th>
      <th>Unique Scenarios</th>
      <th>Vendors</th>
      <th>Models</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Summary</th>
      <td>857</td>
      <td>44</td>
      <td>5</td>
      <td>5</td>
      <td>4</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
            </div>
            
            <div class="section">
                <h2>Score Distributions</h2>
                <p>Distribution of scores across all evaluations:</p>
                <img src="score_distributions.png" alt="Score Distributions">
                <img src="overall_score_distribution.png" alt="Overall Score Distribution">
            </div>
            
            <div class="section">
                <h2>Vendor Comparisons</h2>
                <h3>Average Scores by Vendor</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
    </tr>
    <tr>
      <th>vendor</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Anthropic</th>
      <td>4.084491</td>
      <td>0.646171</td>
      <td>216</td>
    </tr>
    <tr>
      <th>GROK</th>
      <td>4.096698</td>
      <td>0.705489</td>
      <td>212</td>
    </tr>
    <tr>
      <th>Google</th>
      <td>3.823256</td>
      <td>0.764375</td>
      <td>215</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <td>4.012850</td>
      <td>0.659980</td>
      <td>214</td>
    </tr>
  </tbody>
</table>
                
                <h3>Detailed Scores by Vendor</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="3" halign="left">relevance_score</th>
      <th colspan="3" halign="left">correctness_score</th>
      <th colspan="3" halign="left">fluency_score</th>
      <th colspan="3" halign="left">coherence_score</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
    </tr>
    <tr>
      <th>vendor</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Anthropic</th>
      <td>4.138889</td>
      <td>0.727638</td>
      <td>216</td>
      <td>4.013889</td>
      <td>0.762366</td>
      <td>216</td>
      <td>4.120370</td>
      <td>0.803684</td>
      <td>216</td>
      <td>4.064815</td>
      <td>0.810089</td>
      <td>216</td>
    </tr>
    <tr>
      <th>GROK</th>
      <td>4.235849</td>
      <td>0.779499</td>
      <td>212</td>
      <td>4.113208</td>
      <td>0.764382</td>
      <td>212</td>
      <td>4.018868</td>
      <td>0.886776</td>
      <td>212</td>
      <td>4.018868</td>
      <td>0.859639</td>
      <td>212</td>
    </tr>
    <tr>
      <th>Google</th>
      <td>3.906977</td>
      <td>0.848692</td>
      <td>215</td>
      <td>3.744186</td>
      <td>0.934615</td>
      <td>215</td>
      <td>3.860465</td>
      <td>0.890799</td>
      <td>215</td>
      <td>3.781395</td>
      <td>0.913874</td>
      <td>215</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <td>4.065421</td>
      <td>0.747717</td>
      <td>214</td>
      <td>3.967290</td>
      <td>0.795442</td>
      <td>214</td>
      <td>4.000000</td>
      <td>0.793163</td>
      <td>214</td>
      <td>4.018692</td>
      <td>0.786999</td>
      <td>214</td>
    </tr>
  </tbody>
</table>
                
                <h3>Visual Comparisons</h3>
                <img src="vendor_score_comparisons.png" alt="Vendor Score Comparisons">
                <img src="vendor_overall_comparison.png" alt="Vendor Overall Comparison">
                <img src="vendor_metric_averages.png" alt="Vendor Metric Averages">
                
                <h3>Statistical Significance (ANOVA and Tukey HSD)</h3>
                <p>One-way ANOVA tests were conducted to determine if there are statistically significant 
                differences between vendors across evaluation dimensions:</p>
                <table>
                    <tr>
                        <th>Dimension</th>
                        <th>F-statistic</th>
                        <th>p-value</th>
                        <th>Significant</th>
                    </tr>
                    <tr><td>Relevance</td><td>6.8126</td><td>0.0002</td><td>Yes</td></tr><tr><td>Correctness</td><td>7.7965</td><td>0.0000</td><td>Yes</td></tr><tr><td>Fluency</td><td>3.4530</td><td>0.0162</td><td>Yes</td></tr><tr><td>Coherence</td><td>4.9611</td><td>0.0020</td><td>Yes</td></tr><tr><td>Overall</td><td>7.0715</td><td>0.0001</td><td>Yes</td></tr>
                </table>
                
                <p>Where significant differences were found, Tukey HSD post-hoc tests were conducted to 
                identify which specific vendor pairs differed significantly.</p>
            </div>
            
            <div class="section">
                <h2>Model Comparisons</h2>
                <h3>Average Scores by Model</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
    </tr>
    <tr>
      <th>vendor</th>
      <th>model</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.084491</td>
      <td>0.646171</td>
      <td>216</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.096698</td>
      <td>0.705489</td>
      <td>212</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>3.823256</td>
      <td>0.764375</td>
      <td>215</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.012850</td>
      <td>0.659980</td>
      <td>214</td>
    </tr>
  </tbody>
</table>
                
                <h3>Detailed Scores by Model</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th colspan="3" halign="left">relevance_score</th>
      <th colspan="3" halign="left">correctness_score</th>
      <th colspan="3" halign="left">fluency_score</th>
      <th colspan="3" halign="left">coherence_score</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
    </tr>
    <tr>
      <th>vendor</th>
      <th>model</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.138889</td>
      <td>0.727638</td>
      <td>216</td>
      <td>4.013889</td>
      <td>0.762366</td>
      <td>216</td>
      <td>4.120370</td>
      <td>0.803684</td>
      <td>216</td>
      <td>4.064815</td>
      <td>0.810089</td>
      <td>216</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.235849</td>
      <td>0.779499</td>
      <td>212</td>
      <td>4.113208</td>
      <td>0.764382</td>
      <td>212</td>
      <td>4.018868</td>
      <td>0.886776</td>
      <td>212</td>
      <td>4.018868</td>
      <td>0.859639</td>
      <td>212</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>3.906977</td>
      <td>0.848692</td>
      <td>215</td>
      <td>3.744186</td>
      <td>0.934615</td>
      <td>215</td>
      <td>3.860465</td>
      <td>0.890799</td>
      <td>215</td>
      <td>3.781395</td>
      <td>0.913874</td>
      <td>215</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.065421</td>
      <td>0.747717</td>
      <td>214</td>
      <td>3.967290</td>
      <td>0.795442</td>
      <td>214</td>
      <td>4.000000</td>
      <td>0.793163</td>
      <td>214</td>
      <td>4.018692</td>
      <td>0.786999</td>
      <td>214</td>
    </tr>
  </tbody>
</table>
                
                <h3>Visual Comparisons</h3>
                <img src="model_score_comparisons.png" alt="Model Score Comparisons">
                <img src="model_overall_comparison.png" alt="Model Overall Comparison">
                
                <h3>Statistical Significance (ANOVA and Tukey HSD)</h3>
                <p>One-way ANOVA tests were conducted to determine if there are statistically significant 
                differences between models across evaluation dimensions:</p>
                <table>
                    <tr>
                        <th>Dimension</th>
                        <th>F-statistic</th>
                        <th>p-value</th>
                        <th>Significant</th>
                    </tr>
                    <tr><td>Relevance</td><td>6.8126</td><td>0.0002</td><td>Yes</td></tr><tr><td>Correctness</td><td>7.7965</td><td>0.0000</td><td>Yes</td></tr><tr><td>Fluency</td><td>3.4530</td><td>0.0162</td><td>Yes</td></tr><tr><td>Coherence</td><td>4.9611</td><td>0.0020</td><td>Yes</td></tr><tr><td>Overall</td><td>7.0715</td><td>0.0001</td><td>Yes</td></tr>
                </table>
                
                <p>Where significant differences were found, Tukey HSD post-hoc tests were conducted to 
                identify which specific model pairs differed significantly.</p>
            </div>
            
            <div class="section">
                <h2>Confidence Intervals</h2>
                <p>95% confidence intervals for mean scores by vendor:</p>
                <img src="vendor_overall_with_ci.png" alt="Vendor Overall Scores with Confidence Intervals">
                
                <p>These confidence intervals provide a range within which we can be 95% confident that the true mean score lies.</p>
            </div>
            
            <div class="section">
                <h2>Dimension Correlations</h2>
                <p>Pearson correlation analysis between evaluation dimensions:</p>
                <img src="dimension_correlations.png" alt="Dimension Correlations Heatmap">
                
                <p>This correlation matrix shows how strongly the different evaluation dimensions 
                are related to each other. Higher values (closer to 1) indicate stronger positive correlations.</p>
            </div>
            
            <div class="section">
                <h2>Principal Component Analysis</h2>
                <p>PCA was performed to identify underlying patterns in evaluator ratings:</p>
                <img src="pca_explained_variance.png" alt="PCA Explained Variance">
                <img src="pca_components.png" alt="PCA Components">
                
                <p>The PCA plot shows how the evaluation dimensions relate to each other in a reduced 
                dimensional space. Points represent individual evaluations, and their colors indicate 
                the overall score. The arrows show how the original dimensions contribute to the principal components.</p>
            </div>
            
            <div class="section">
                <h2>Scenario Coverage</h2>
                <p>Number of evaluations by scenario:</p>
                <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>case_id</th>
      <th>scenario_filename</th>
      <th>iteration</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <th>1_case.md</th>
      <th>1</th>
      <td>171</td>
    </tr>
    <tr>
      <th>2</th>
      <th>2_case.md</th>
      <th>1</th>
      <td>171</td>
    </tr>
    <tr>
      <th>3</th>
      <th>3_case.md</th>
      <th>1</th>
      <td>170</td>
    </tr>
    <tr>
      <th>4</th>
      <th>4_case.md</th>
      <th>1</th>
      <td>170</td>
    </tr>
    <tr>
      <th>5</th>
      <th>5_case.md</th>
      <th>1</th>
      <td>175</td>
    </tr>
  </tbody>
</table>
            </div>
            
            <div class="section">
                <h2>Iteration Analysis</h2>
                <h3>Scores by Iteration Number</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="3" halign="left">relevance_score</th>
      <th colspan="3" halign="left">correctness_score</th>
      <th colspan="3" halign="left">fluency_score</th>
      <th colspan="3" halign="left">coherence_score</th>
      <th colspan="3" halign="left">overall_score</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
    </tr>
    <tr>
      <th>iteration</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>4.086348</td>
      <td>0.785091</td>
      <td>857</td>
      <td>3.95916</td>
      <td>0.82709</td>
      <td>857</td>
      <td>4.0</td>
      <td>0.848308</td>
      <td>857</td>
      <td>3.970828</td>
      <td>0.84987</td>
      <td>857</td>
      <td>4.004084</td>
      <td>0.702849</td>
      <td>857</td>
    </tr>
  </tbody>
</table>
                
                <h3>Vendor Performance by Iteration</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th colspan="3" halign="left">overall_score</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
    </tr>
    <tr>
      <th>vendor</th>
      <th>iteration</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Anthropic</th>
      <th>1</th>
      <td>4.084491</td>
      <td>0.646171</td>
      <td>216</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>1</th>
      <td>4.096698</td>
      <td>0.705489</td>
      <td>212</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>1</th>
      <td>3.823256</td>
      <td>0.764375</td>
      <td>215</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>1</th>
      <td>4.012850</td>
      <td>0.659980</td>
      <td>214</td>
    </tr>
  </tbody>
</table>
                
                <p>Comparison of overall scores across iterations:</p>
                <img src="iteration_comparison.png" alt="Iteration Comparison">
            </div>
            
            <div class="section">
                <h2>Scenario Analysis</h2>
                <h3>Scores by Scenario</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="3" halign="left">relevance_score</th>
      <th colspan="3" halign="left">correctness_score</th>
      <th colspan="3" halign="left">fluency_score</th>
      <th colspan="3" halign="left">coherence_score</th>
      <th colspan="3" halign="left">overall_score</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
    </tr>
    <tr>
      <th>scenario_id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1-1_case.md</th>
      <td>4.081871</td>
      <td>0.807515</td>
      <td>171</td>
      <td>3.976608</td>
      <td>0.846816</td>
      <td>171</td>
      <td>4.046784</td>
      <td>0.817549</td>
      <td>171</td>
      <td>3.959064</td>
      <td>0.903306</td>
      <td>171</td>
      <td>4.016082</td>
      <td>0.710813</td>
      <td>171</td>
    </tr>
    <tr>
      <th>2-2_case.md</th>
      <td>4.175439</td>
      <td>0.784920</td>
      <td>171</td>
      <td>3.988304</td>
      <td>0.847059</td>
      <td>171</td>
      <td>3.988304</td>
      <td>0.867643</td>
      <td>171</td>
      <td>4.011696</td>
      <td>0.853976</td>
      <td>171</td>
      <td>4.040936</td>
      <td>0.699636</td>
      <td>171</td>
    </tr>
    <tr>
      <th>3-3_case.md</th>
      <td>4.023529</td>
      <td>0.799060</td>
      <td>170</td>
      <td>3.841176</td>
      <td>0.823874</td>
      <td>170</td>
      <td>3.958824</td>
      <td>0.816660</td>
      <td>170</td>
      <td>3.835294</td>
      <td>0.847510</td>
      <td>170</td>
      <td>3.914706</td>
      <td>0.710293</td>
      <td>170</td>
    </tr>
    <tr>
      <th>4-4_case.md</th>
      <td>4.088235</td>
      <td>0.805589</td>
      <td>170</td>
      <td>4.000000</td>
      <td>0.856579</td>
      <td>170</td>
      <td>4.076471</td>
      <td>0.842671</td>
      <td>170</td>
      <td>4.023529</td>
      <td>0.856254</td>
      <td>170</td>
      <td>4.047059</td>
      <td>0.713867</td>
      <td>170</td>
    </tr>
    <tr>
      <th>5-5_case.md</th>
      <td>4.062857</td>
      <td>0.728361</td>
      <td>175</td>
      <td>3.988571</td>
      <td>0.758011</td>
      <td>175</td>
      <td>3.931429</td>
      <td>0.894354</td>
      <td>175</td>
      <td>4.022857</td>
      <td>0.780173</td>
      <td>175</td>
      <td>4.001429</td>
      <td>0.679914</td>
      <td>175</td>
    </tr>
  </tbody>
</table>
                
                <h3>Model Performance by Scenario</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th colspan="2" halign="left">relevance_score</th>
      <th colspan="2" halign="left">correctness_score</th>
      <th colspan="2" halign="left">fluency_score</th>
      <th colspan="2" halign="left">coherence_score</th>
      <th colspan="2" halign="left">overall_score</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
    </tr>
    <tr>
      <th>scenario_id</th>
      <th>vendor</th>
      <th>model</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="4" valign="top">1-1_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.250000</td>
      <td>0.575669</td>
      <td>4.159091</td>
      <td>0.568277</td>
      <td>4.272727</td>
      <td>0.694284</td>
      <td>4.227273</td>
      <td>0.742830</td>
      <td>4.227273</td>
      <td>0.505258</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.166667</td>
      <td>0.823931</td>
      <td>4.000000</td>
      <td>0.826394</td>
      <td>3.785714</td>
      <td>0.950884</td>
      <td>3.833333</td>
      <td>0.960606</td>
      <td>3.946429</td>
      <td>0.758158</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>3.809524</td>
      <td>0.916997</td>
      <td>3.595238</td>
      <td>1.060592</td>
      <td>3.904762</td>
      <td>0.758996</td>
      <td>3.619048</td>
      <td>1.010973</td>
      <td>3.732143</td>
      <td>0.814115</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.093023</td>
      <td>0.839897</td>
      <td>4.139535</td>
      <td>0.774025</td>
      <td>4.209302</td>
      <td>0.773309</td>
      <td>4.139535</td>
      <td>0.774025</td>
      <td>4.145349</td>
      <td>0.652907</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">2-2_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.190476</td>
      <td>0.803592</td>
      <td>4.071429</td>
      <td>0.947213</td>
      <td>4.071429</td>
      <td>0.866528</td>
      <td>4.119048</td>
      <td>0.832346</td>
      <td>4.113095</td>
      <td>0.730858</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.418605</td>
      <td>0.626120</td>
      <td>4.093023</td>
      <td>0.717600</td>
      <td>4.093023</td>
      <td>0.867782</td>
      <td>4.162791</td>
      <td>0.843186</td>
      <td>4.191860</td>
      <td>0.621627</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>3.886364</td>
      <td>0.894841</td>
      <td>3.750000</td>
      <td>0.866025</td>
      <td>3.681818</td>
      <td>0.909197</td>
      <td>3.681818</td>
      <td>0.856513</td>
      <td>3.750000</td>
      <td>0.713247</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.214286</td>
      <td>0.716894</td>
      <td>4.047619</td>
      <td>0.824987</td>
      <td>4.119048</td>
      <td>0.771517</td>
      <td>4.095238</td>
      <td>0.820753</td>
      <td>4.119048</td>
      <td>0.663137</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">3-3_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>3.976190</td>
      <td>0.780497</td>
      <td>3.880952</td>
      <td>0.705462</td>
      <td>4.023810</td>
      <td>0.780497</td>
      <td>3.880952</td>
      <td>0.802508</td>
      <td>3.940476</td>
      <td>0.621783</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.238095</td>
      <td>0.790478</td>
      <td>4.142857</td>
      <td>0.783097</td>
      <td>4.190476</td>
      <td>0.833391</td>
      <td>4.047619</td>
      <td>0.882137</td>
      <td>4.154762</td>
      <td>0.715577</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>4.000000</td>
      <td>0.845154</td>
      <td>3.744186</td>
      <td>0.902194</td>
      <td>3.930233</td>
      <td>0.856220</td>
      <td>3.744186</td>
      <td>0.902194</td>
      <td>3.854651</td>
      <td>0.775811</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>3.883721</td>
      <td>0.762493</td>
      <td>3.604651</td>
      <td>0.820555</td>
      <td>3.697674</td>
      <td>0.741134</td>
      <td>3.674419</td>
      <td>0.778305</td>
      <td>3.715116</td>
      <td>0.669447</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">4-4_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.142857</td>
      <td>0.751305</td>
      <td>3.904762</td>
      <td>0.790478</td>
      <td>4.166667</td>
      <td>0.908407</td>
      <td>4.000000</td>
      <td>0.910642</td>
      <td>4.053571</td>
      <td>0.718942</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.162791</td>
      <td>0.897887</td>
      <td>4.186047</td>
      <td>0.852331</td>
      <td>4.000000</td>
      <td>0.899735</td>
      <td>4.046512</td>
      <td>0.871602</td>
      <td>4.098837</td>
      <td>0.785167</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>4.000000</td>
      <td>0.845154</td>
      <td>3.860465</td>
      <td>0.989983</td>
      <td>4.116279</td>
      <td>0.822577</td>
      <td>3.976744</td>
      <td>0.858802</td>
      <td>3.988372</td>
      <td>0.757804</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.047619</td>
      <td>0.730933</td>
      <td>4.047619</td>
      <td>0.763573</td>
      <td>4.023810</td>
      <td>0.748595</td>
      <td>4.071429</td>
      <td>0.808276</td>
      <td>4.047619</td>
      <td>0.597857</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">5-5_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.130435</td>
      <td>0.718291</td>
      <td>4.043478</td>
      <td>0.758845</td>
      <td>4.065217</td>
      <td>0.771785</td>
      <td>4.086957</td>
      <td>0.755015</td>
      <td>4.081522</td>
      <td>0.632575</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.190476</td>
      <td>0.740405</td>
      <td>4.142857</td>
      <td>0.646621</td>
      <td>4.023810</td>
      <td>0.869205</td>
      <td>4.000000</td>
      <td>0.732520</td>
      <td>4.089286</td>
      <td>0.641125</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>3.837209</td>
      <td>0.753728</td>
      <td>3.767442</td>
      <td>0.868420</td>
      <td>3.674419</td>
      <td>1.040168</td>
      <td>3.883721</td>
      <td>0.931187</td>
      <td>3.790698</td>
      <td>0.767514</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.090909</td>
      <td>0.675766</td>
      <td>4.000000</td>
      <td>0.715282</td>
      <td>3.954545</td>
      <td>0.861436</td>
      <td>4.113636</td>
      <td>0.689317</td>
      <td>4.039773</td>
      <td>0.651347</td>
    </tr>
  </tbody>
</table>
                
                <p>Visual comparisons of scores by scenario:</p>
                <img src="scenario_overall_scores.png" alt="Scenario Overall Scores">
                <img src="scenario_metric_heatmap.png" alt="Scenario Metric Heatmap">
                <img src="scenario_model_heatmap.png" alt="Model Performance by Scenario">
            </div>
            
            <div class="section">
                <h2>Evaluator Participation</h2>
                <p>Number of evaluations by evaluator ID:</p>
                <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
    <tr>
      <th>evaluator_id</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>21</td>
    </tr>
    <tr>
      <th>10</th>
      <td>20</td>
    </tr>
    <tr>
      <th>11</th>
      <td>20</td>
    </tr>
    <tr>
      <th>13</th>
      <td>20</td>
    </tr>
    <tr>
      <th>14</th>
      <td>20</td>
    </tr>
    <tr>
      <th>15</th>
      <td>20</td>
    </tr>
    <tr>
      <th>16</th>
      <td>20</td>
    </tr>
    <tr>
      <th>17</th>
      <td>20</td>
    </tr>
    <tr>
      <th>18</th>
      <td>20</td>
    </tr>
    <tr>
      <th>19</th>
      <td>5</td>
    </tr>
    <tr>
      <th>20</th>
      <td>20</td>
    </tr>
    <tr>
      <th>21</th>
      <td>20</td>
    </tr>
    <tr>
      <th>22</th>
      <td>20</td>
    </tr>
    <tr>
      <th>23</th>
      <td>20</td>
    </tr>
    <tr>
      <th>24</th>
      <td>20</td>
    </tr>
    <tr>
      <th>25</th>
      <td>20</td>
    </tr>
    <tr>
      <th>26</th>
      <td>20</td>
    </tr>
    <tr>
      <th>27</th>
      <td>22</td>
    </tr>
    <tr>
      <th>28</th>
      <td>20</td>
    </tr>
    <tr>
      <th>29</th>
      <td>20</td>
    </tr>
    <tr>
      <th>30</th>
      <td>20</td>
    </tr>
    <tr>
      <th>31</th>
      <td>20</td>
    </tr>
    <tr>
      <th>32</th>
      <td>21</td>
    </tr>
    <tr>
      <th>33</th>
      <td>21</td>
    </tr>
    <tr>
      <th>34</th>
      <td>20</td>
    </tr>
    <tr>
      <th>35</th>
      <td>20</td>
    </tr>
    <tr>
      <th>36</th>
      <td>20</td>
    </tr>
    <tr>
      <th>37</th>
      <td>20</td>
    </tr>
    <tr>
      <th>38</th>
      <td>20</td>
    </tr>
    <tr>
      <th>39</th>
      <td>21</td>
    </tr>
    <tr>
      <th>40</th>
      <td>20</td>
    </tr>
    <tr>
      <th>41</th>
      <td>20</td>
    </tr>
    <tr>
      <th>42</th>
      <td>20</td>
    </tr>
    <tr>
      <th>43</th>
      <td>20</td>
    </tr>
    <tr>
      <th>44</th>
      <td>20</td>
    </tr>
    <tr>
      <th>45</th>
      <td>20</td>
    </tr>
    <tr>
      <th>46</th>
      <td>20</td>
    </tr>
    <tr>
      <th>47</th>
      <td>20</td>
    </tr>
    <tr>
      <th>48</th>
      <td>20</td>
    </tr>
    <tr>
      <th>49</th>
      <td>21</td>
    </tr>
    <tr>
      <th>50</th>
      <td>20</td>
    </tr>
    <tr>
      <th>51</th>
      <td>5</td>
    </tr>
    <tr>
      <th>52</th>
      <td>20</td>
    </tr>
    <tr>
      <th>53</th>
      <td>20</td>
    </tr>
  </tbody>
</table>
            </div>

            <div class="section">
                <h2>Detailed Scenario Analysis</h2>
                
                <h3>Scenario Types</h3>
                <table class="scenario-types">
                    <tr>
                        <th>Case Number</th>
                        <th>Type</th>
                    </tr>
                    <tr><td>Case 1</td><td>cultural</td></tr><tr><td>Case 1</td><td>cultural</td></tr><tr><td>Case 2</td><td>self-harm</td></tr><tr><td>Case 2</td><td>self-harm</td></tr><tr><td>Case 3</td><td>addiction</td></tr><tr><td>Case 3</td><td>addiction</td></tr><tr><td>Case 4</td><td>reproduction</td></tr><tr><td>Case 4</td><td>reproduction</td></tr><tr><td>Case 5</td><td>end of life management</td></tr><tr><td>Case 5</td><td>end of life management</td></tr>
                </table>
                
                <h3>Overall Metrics by Scenario</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="3" halign="left">relevance_score</th>
      <th colspan="3" halign="left">correctness_score</th>
      <th colspan="3" halign="left">fluency_score</th>
      <th colspan="3" halign="left">coherence_score</th>
      <th colspan="3" halign="left">overall_score</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>count</th>
    </tr>
    <tr>
      <th>scenario_id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1-1_case.md</th>
      <td>4.081871</td>
      <td>0.807515</td>
      <td>171</td>
      <td>3.976608</td>
      <td>0.846816</td>
      <td>171</td>
      <td>4.046784</td>
      <td>0.817549</td>
      <td>171</td>
      <td>3.959064</td>
      <td>0.903306</td>
      <td>171</td>
      <td>4.016082</td>
      <td>0.710813</td>
      <td>171</td>
    </tr>
    <tr>
      <th>2-2_case.md</th>
      <td>4.175439</td>
      <td>0.784920</td>
      <td>171</td>
      <td>3.988304</td>
      <td>0.847059</td>
      <td>171</td>
      <td>3.988304</td>
      <td>0.867643</td>
      <td>171</td>
      <td>4.011696</td>
      <td>0.853976</td>
      <td>171</td>
      <td>4.040936</td>
      <td>0.699636</td>
      <td>171</td>
    </tr>
    <tr>
      <th>3-3_case.md</th>
      <td>4.023529</td>
      <td>0.799060</td>
      <td>170</td>
      <td>3.841176</td>
      <td>0.823874</td>
      <td>170</td>
      <td>3.958824</td>
      <td>0.816660</td>
      <td>170</td>
      <td>3.835294</td>
      <td>0.847510</td>
      <td>170</td>
      <td>3.914706</td>
      <td>0.710293</td>
      <td>170</td>
    </tr>
    <tr>
      <th>4-4_case.md</th>
      <td>4.088235</td>
      <td>0.805589</td>
      <td>170</td>
      <td>4.000000</td>
      <td>0.856579</td>
      <td>170</td>
      <td>4.076471</td>
      <td>0.842671</td>
      <td>170</td>
      <td>4.023529</td>
      <td>0.856254</td>
      <td>170</td>
      <td>4.047059</td>
      <td>0.713867</td>
      <td>170</td>
    </tr>
    <tr>
      <th>5-5_case.md</th>
      <td>4.062857</td>
      <td>0.728361</td>
      <td>175</td>
      <td>3.988571</td>
      <td>0.758011</td>
      <td>175</td>
      <td>3.931429</td>
      <td>0.894354</td>
      <td>175</td>
      <td>4.022857</td>
      <td>0.780173</td>
      <td>175</td>
      <td>4.001429</td>
      <td>0.679914</td>
      <td>175</td>
    </tr>
  </tbody>
</table>
                
                <h3>Model Performance by Scenario</h3>
                <table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th colspan="2" halign="left">relevance_score</th>
      <th colspan="2" halign="left">correctness_score</th>
      <th colspan="2" halign="left">fluency_score</th>
      <th colspan="2" halign="left">coherence_score</th>
      <th colspan="2" halign="left">overall_score</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
      <th>mean</th>
      <th>std</th>
    </tr>
    <tr>
      <th>scenario_id</th>
      <th>vendor</th>
      <th>model</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="4" valign="top">1-1_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.250000</td>
      <td>0.575669</td>
      <td>4.159091</td>
      <td>0.568277</td>
      <td>4.272727</td>
      <td>0.694284</td>
      <td>4.227273</td>
      <td>0.742830</td>
      <td>4.227273</td>
      <td>0.505258</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.166667</td>
      <td>0.823931</td>
      <td>4.000000</td>
      <td>0.826394</td>
      <td>3.785714</td>
      <td>0.950884</td>
      <td>3.833333</td>
      <td>0.960606</td>
      <td>3.946429</td>
      <td>0.758158</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>3.809524</td>
      <td>0.916997</td>
      <td>3.595238</td>
      <td>1.060592</td>
      <td>3.904762</td>
      <td>0.758996</td>
      <td>3.619048</td>
      <td>1.010973</td>
      <td>3.732143</td>
      <td>0.814115</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.093023</td>
      <td>0.839897</td>
      <td>4.139535</td>
      <td>0.774025</td>
      <td>4.209302</td>
      <td>0.773309</td>
      <td>4.139535</td>
      <td>0.774025</td>
      <td>4.145349</td>
      <td>0.652907</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">2-2_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.190476</td>
      <td>0.803592</td>
      <td>4.071429</td>
      <td>0.947213</td>
      <td>4.071429</td>
      <td>0.866528</td>
      <td>4.119048</td>
      <td>0.832346</td>
      <td>4.113095</td>
      <td>0.730858</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.418605</td>
      <td>0.626120</td>
      <td>4.093023</td>
      <td>0.717600</td>
      <td>4.093023</td>
      <td>0.867782</td>
      <td>4.162791</td>
      <td>0.843186</td>
      <td>4.191860</td>
      <td>0.621627</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>3.886364</td>
      <td>0.894841</td>
      <td>3.750000</td>
      <td>0.866025</td>
      <td>3.681818</td>
      <td>0.909197</td>
      <td>3.681818</td>
      <td>0.856513</td>
      <td>3.750000</td>
      <td>0.713247</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.214286</td>
      <td>0.716894</td>
      <td>4.047619</td>
      <td>0.824987</td>
      <td>4.119048</td>
      <td>0.771517</td>
      <td>4.095238</td>
      <td>0.820753</td>
      <td>4.119048</td>
      <td>0.663137</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">3-3_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>3.976190</td>
      <td>0.780497</td>
      <td>3.880952</td>
      <td>0.705462</td>
      <td>4.023810</td>
      <td>0.780497</td>
      <td>3.880952</td>
      <td>0.802508</td>
      <td>3.940476</td>
      <td>0.621783</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.238095</td>
      <td>0.790478</td>
      <td>4.142857</td>
      <td>0.783097</td>
      <td>4.190476</td>
      <td>0.833391</td>
      <td>4.047619</td>
      <td>0.882137</td>
      <td>4.154762</td>
      <td>0.715577</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>4.000000</td>
      <td>0.845154</td>
      <td>3.744186</td>
      <td>0.902194</td>
      <td>3.930233</td>
      <td>0.856220</td>
      <td>3.744186</td>
      <td>0.902194</td>
      <td>3.854651</td>
      <td>0.775811</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>3.883721</td>
      <td>0.762493</td>
      <td>3.604651</td>
      <td>0.820555</td>
      <td>3.697674</td>
      <td>0.741134</td>
      <td>3.674419</td>
      <td>0.778305</td>
      <td>3.715116</td>
      <td>0.669447</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">4-4_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.142857</td>
      <td>0.751305</td>
      <td>3.904762</td>
      <td>0.790478</td>
      <td>4.166667</td>
      <td>0.908407</td>
      <td>4.000000</td>
      <td>0.910642</td>
      <td>4.053571</td>
      <td>0.718942</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.162791</td>
      <td>0.897887</td>
      <td>4.186047</td>
      <td>0.852331</td>
      <td>4.000000</td>
      <td>0.899735</td>
      <td>4.046512</td>
      <td>0.871602</td>
      <td>4.098837</td>
      <td>0.785167</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>4.000000</td>
      <td>0.845154</td>
      <td>3.860465</td>
      <td>0.989983</td>
      <td>4.116279</td>
      <td>0.822577</td>
      <td>3.976744</td>
      <td>0.858802</td>
      <td>3.988372</td>
      <td>0.757804</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.047619</td>
      <td>0.730933</td>
      <td>4.047619</td>
      <td>0.763573</td>
      <td>4.023810</td>
      <td>0.748595</td>
      <td>4.071429</td>
      <td>0.808276</td>
      <td>4.047619</td>
      <td>0.597857</td>
    </tr>
    <tr>
      <th rowspan="4" valign="top">5-5_case.md</th>
      <th>Anthropic</th>
      <th>claude-3-opus-20240229</th>
      <td>4.130435</td>
      <td>0.718291</td>
      <td>4.043478</td>
      <td>0.758845</td>
      <td>4.065217</td>
      <td>0.771785</td>
      <td>4.086957</td>
      <td>0.755015</td>
      <td>4.081522</td>
      <td>0.632575</td>
    </tr>
    <tr>
      <th>GROK</th>
      <th>grok-3-mini</th>
      <td>4.190476</td>
      <td>0.740405</td>
      <td>4.142857</td>
      <td>0.646621</td>
      <td>4.023810</td>
      <td>0.869205</td>
      <td>4.000000</td>
      <td>0.732520</td>
      <td>4.089286</td>
      <td>0.641125</td>
    </tr>
    <tr>
      <th>Google</th>
      <th>gemini-1.5-pro</th>
      <td>3.837209</td>
      <td>0.753728</td>
      <td>3.767442</td>
      <td>0.868420</td>
      <td>3.674419</td>
      <td>1.040168</td>
      <td>3.883721</td>
      <td>0.931187</td>
      <td>3.790698</td>
      <td>0.767514</td>
    </tr>
    <tr>
      <th>OpenAI</th>
      <th>gpt-4.1-nano</th>
      <td>4.090909</td>
      <td>0.675766</td>
      <td>4.000000</td>
      <td>0.715282</td>
      <td>3.954545</td>
      <td>0.861436</td>
      <td>4.113636</td>
      <td>0.689317</td>
      <td>4.039773</td>
      <td>0.651347</td>
    </tr>
  </tbody>
</table>
                
                <h3>Visual Analysis</h3>
                <h4>Overall Performance</h4>
                <img src="scenario_overall_scores.png" alt="Scenario Overall Scores">
                <img src="scenario_metric_heatmap.png" alt="Scenario Metric Heatmap">
                <img src="scenario_model_heatmap.png" alt="Scenario Model Performance Heatmap">
                
                <h4>Detailed Metric Analysis by Scenario</h4>
                <p>The following charts show how each vendor performed across different scenarios for each evaluation metric:</p>
                
                <div class="metric-charts">
                    <h5>Relevance Scores</h5>
                    <img src="scenario_relevance_score_line_chart.png" alt="Relevance Scores by Scenario and Vendor">
                    
                    <h5>Correctness Scores</h5>
                    <img src="scenario_correctness_score_line_chart.png" alt="Correctness Scores by Scenario and Vendor">
                    
                    <h5>Fluency Scores</h5>
                    <img src="scenario_fluency_score_line_chart.png" alt="Fluency Scores by Scenario and Vendor">
                    
                    <h5>Coherence Scores</h5>
                    <img src="scenario_coherence_score_line_chart.png" alt="Coherence Scores by Scenario and Vendor">
                    
                    <h5>Overall Scores</h5>
                    <img src="scenario_overall_score_line_chart.png" alt="Overall Scores by Scenario and Vendor">
                </div>
                
                <p>This section provides a detailed breakdown of how different models performed across various scenarios,
                allowing us to identify patterns in model performance across different types of cases. The line charts
                above show the progression of scores across scenarios for each vendor, making it easy to identify:
                <ul>
                    <li>Which vendors consistently perform better for specific metrics</li>
                    <li>How performance varies across different scenarios</li>
                    <li>Where there are significant gaps in performance between vendors</li>
                    <li>Which scenarios are particularly challenging or easy for specific vendors</li>
                </ul>
                </p>
            </div>
        </body>
        </html>